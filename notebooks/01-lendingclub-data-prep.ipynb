{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f95a55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download of 'accepted_2007_to_2018Q4.csv.gz'...\n",
      "This may take a few minutes...\n",
      "Dataset URL: https://www.kaggle.com/datasets/wordsforthewise/lending-club\n",
      "accepted_2007_to_2018Q4.csv.gz: Skipping, found more recently modified local copy (use --force to force download)\n",
      "\n",
      "Download complete.\n",
      "\n",
      "Starting optimized loading of the dataset...\n",
      "SUCCESS! Loaded 2260701 rows and 15 columns.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2260701 entries, 0 to 2260700\n",
      "Data columns (total 15 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   loan_amnt            float64\n",
      " 1   term                 object \n",
      " 2   int_rate             float64\n",
      " 3   grade                object \n",
      " 4   sub_grade            object \n",
      " 5   emp_length           object \n",
      " 6   home_ownership       object \n",
      " 7   annual_inc           float64\n",
      " 8   verification_status  object \n",
      " 9   issue_d              object \n",
      " 10  loan_status          object \n",
      " 11  purpose              object \n",
      " 12  addr_state           object \n",
      " 13  dti                  float64\n",
      " 14  earliest_cr_line     object \n",
      "dtypes: float64(4), object(11)\n",
      "memory usage: 258.7+ MB\n"
     ]
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "dataset_slug = 'wordsforthewise/lending-club'\n",
    "\n",
    "# The exact filename we want to download\n",
    "file_to_download = 'accepted_2007_to_2018Q4.csv.gz'\n",
    "\n",
    "# Where we want to save the file (in the current 'notebooks' folder)\n",
    "output_path = '.' # '.' means the current directory\n",
    "\n",
    "# --- 2. Download the Specific File ---\n",
    "print(f\"Starting download of '{file_to_download}'...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "try:\n",
    "    # Check if the uncompressed file already exists to avoid re-downloading\n",
    "    if not os.path.exists('accepted_2007_to_2018Q4.csv'):\n",
    "        api.dataset_download_file(dataset_slug,\n",
    "                                  file_name=file_to_download,\n",
    "                                  path=output_path,\n",
    "                                  quiet=False) # quiet=False shows the progress bar\n",
    "        \n",
    "        # The Kaggle API downloads the .gz file, which Pandas can read directly.\n",
    "        print(\"\\nDownload complete.\")\n",
    "    else:\n",
    "        print(\"\\nMain data file already exists. Skipping download.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during download: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- 3. Optimized Loading (Reading the .gz file directly) ---\n",
    "# Now, the final step: load the data using 'usecols'.\n",
    "# Pandas is smart and can decompress the .gz file in real-time.\n",
    "\n",
    "relevant_columns = [\n",
    "    'loan_amnt', 'term', 'int_rate', 'grade', 'sub_grade', 'emp_length',\n",
    "    'home_ownership', 'annual_inc', 'verification_status', 'loan_status',\n",
    "    'purpose', 'addr_state', 'dti', 'issue_d', 'earliest_cr_line'\n",
    "]\n",
    "\n",
    "print(\"\\nStarting optimized loading of the dataset...\")\n",
    "try:\n",
    "    # We use the name of the downloaded compressed file.\n",
    "    # Pandas reads the compressed file directly!\n",
    "    df = pd.read_csv('accepted_2007_to_2018Q4.csv.gz', \n",
    "                     usecols=relevant_columns, \n",
    "                     compression='gzip', # Tells Pandas it's a gzip file\n",
    "                     low_memory=False)\n",
    "    \n",
    "    print(f\"SUCCESS! Loaded {len(df)} rows and {len(df.columns)} columns.\")\n",
    "    df.info()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during loading: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7f2dd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of 'Good' vs 'Bad' loans:\n",
      "loan_condition\n",
      "Good    1957056\n",
      "Bad      303612\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Map detailed loan statuses to simple 'Good' or 'Bad' categories for analysis\n",
    "def map_loan_status(status):\n",
    "    # We consider 'Fully Paid' and 'Current' loans as \"Good\"\n",
    "    if status in ['Fully Paid', 'Current', 'Does not meet the credit policy. Status:Fully Paid']:\n",
    "        return 'Good'\n",
    "    # All other statuses for accepted loans that were not fully paid are considered \"Bad\" for risk analysis\n",
    "    elif status in ['Charged Off', 'Default', 'Late (31-120 days)', 'In Grace Period', 'Late (16-30 days)', 'Does not meet the credit policy. Status:Charged Off']:\n",
    "        return 'Bad'\n",
    "    return 'Other' # Status that don't fit (rare at this stage)\n",
    "\n",
    "# Apply the function to create the new target column\n",
    "df['loan_condition'] = df['loan_status'].apply(map_loan_status)\n",
    "\n",
    "# Filter to keep only loans with a defined final outcome (Good or Bad)\n",
    "# and create a copy to avoid SettingWithCopyWarning\n",
    "df_final = df[df['loan_condition'].isin(['Good', 'Bad'])].copy()\n",
    "\n",
    "print(\"Count of 'Good' vs 'Bad' loans:\")\n",
    "print(df_final['loan_condition'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbaeca08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaning 'term' and 'emp_length' columns...\n",
      "'term' column cleaned successfully.\n",
      "'emp_length' column cleaned successfully.\n",
      "\n",
      "Cleaning complete.\n",
      "\n",
      "Unique values for 'term': [np.int64(36), np.int64(60)]\n",
      "Unique values for 'emp_length': [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10)]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCleaning 'term' and 'emp_length' columns...\")\n",
    "\n",
    "# --- ROBUST CLEANING OF 'term' COLUMN ---\n",
    "# Step 1: Ensure all values in the 'term' column are strings, handling nulls.\n",
    "df_final['term'] = df_final['term'].astype(str)\n",
    "\n",
    "# Step 2: Now, safely remove the text and convert to integer.\n",
    "df_final['term'] = df_final['term'].str.replace(' months', '').astype(int)\n",
    "print(\"'term' column cleaned successfully.\")\n",
    "\n",
    "\n",
    "# --- ROBUST CLEANING OF 'emp_length' COLUMN ---\n",
    "# Step 1: Ensure all values in the 'emp_length' column are strings, handling nulls.\n",
    "df_final['emp_length'] = df_final['emp_length'].astype(str)\n",
    "\n",
    "# Step 2: Now, safely perform the text replacements.\n",
    "df_final['emp_length'] = df_final['emp_length'].str.replace('< 1 year', '0')\n",
    "df_final['emp_length'] = df_final['emp_length'].str.replace(' years', '')\n",
    "df_final['emp_length'] = df_final['emp_length'].str.replace(' year', '')\n",
    "df_final['emp_length'] = df_final['emp_length'].str.replace('+', '')\n",
    "df_final['emp_length'] = df_final['emp_length'].str.replace('nan', '0') # Handles nulls that became the string 'nan'\n",
    "\n",
    "# Step 3: Convert the cleaned column to a numeric type.\n",
    "df_final['emp_length'] = pd.to_numeric(df_final['emp_length'])\n",
    "print(\"'emp_length' column cleaned successfully.\")\n",
    "\n",
    "\n",
    "print(\"\\nCleaning complete.\")\n",
    "print(\"\\nUnique values for 'term':\", sorted(df_final['term'].unique()))\n",
    "print(\"Unique values for 'emp_length':\", sorted(df_final['emp_length'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8290ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting 'issue_d' column to datetime format...\n",
      "Date conversion complete.\n",
      "     issue_d\n",
      "0 2015-12-01\n",
      "1 2015-12-01\n",
      "2 2015-12-01\n",
      "3 2015-12-01\n",
      "4 2015-12-01\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConverting 'issue_d' column to datetime format...\")\n",
    "\n",
    "# Convert the loan issue date column\n",
    "df_final['issue_d'] = pd.to_datetime(df_final['issue_d'], format='%b-%Y')\n",
    "\n",
    "print(\"Date conversion complete.\")\n",
    "print(df_final[['issue_d']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1976262d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting final data type adjustments...\n",
      "- 'loan_amnt' column converted to Integer.\n",
      "- Float columns rounded for better display.\n",
      "\n",
      "--- Checking final data types before saving ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2260668 entries, 0 to 2260698\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Dtype         \n",
      "---  ------               -----         \n",
      " 0   loan_amnt            Int64         \n",
      " 1   term                 int64         \n",
      " 2   int_rate             float64       \n",
      " 3   grade                object        \n",
      " 4   sub_grade            object        \n",
      " 5   emp_length           int64         \n",
      " 6   home_ownership       object        \n",
      " 7   annual_inc           float64       \n",
      " 8   verification_status  object        \n",
      " 9   issue_d              datetime64[ns]\n",
      " 10  loan_status          object        \n",
      " 11  purpose              object        \n",
      " 12  addr_state           object        \n",
      " 13  dti                  float64       \n",
      " 14  earliest_cr_line     object        \n",
      " 15  loan_condition       object        \n",
      "dtypes: Int64(1), datetime64[ns](1), float64(3), int64(2), object(9)\n",
      "memory usage: 295.4+ MB\n",
      "None\n",
      "\n",
      "--- Checking final descriptive statistics ---\n",
      "          loan_amnt      int_rate    annual_inc           dti\n",
      "count     2260668.0  2.260668e+06  2.260664e+06  2.258957e+06\n",
      "mean   15046.931228  1.309283e+01  7.799243e+04  1.882420e+01\n",
      "std     9190.245488  4.832138e+00  1.126962e+05  1.418333e+01\n",
      "min           500.0  5.310000e+00  0.000000e+00 -1.000000e+00\n",
      "25%          8000.0  9.490000e+00  4.600000e+04  1.189000e+01\n",
      "50%         12900.0  1.262000e+01  6.500000e+04  1.784000e+01\n",
      "75%         20000.0  1.599000e+01  9.300000e+04  2.449000e+01\n",
      "max         40000.0  3.099000e+01  1.100000e+08  9.990000e+02\n"
     ]
    }
   ],
   "source": [
    "# --- FINAL DATA TYPE ADJUSTMENT AND VALIDATION CELL ---\n",
    "\n",
    "print(\"\\nStarting final data type adjustments...\")\n",
    "\n",
    "# 1. Convert 'loan_amnt' to integer, if possible.\n",
    "# We use 'Int64' (with a capital 'I'), a special Pandas type\n",
    "# that supports integers even with null values (not our case, but it's good practice).\n",
    "try:\n",
    "    df_final['loan_amnt'] = df_final['loan_amnt'].astype('Int64')\n",
    "    print(\"- 'loan_amnt' column converted to Integer.\")\n",
    "except Exception as e:\n",
    "    print(f\"- WARNING: Could not convert 'loan_amnt' to integer. Error: {e}\")\n",
    "\n",
    "\n",
    "# 2. Round other float columns to a reasonable number of decimal places.\n",
    "# This improves their appearance in Tableau.\n",
    "df_final['int_rate'] = df_final['int_rate'].round(2)\n",
    "df_final['annual_inc'] = df_final['annual_inc'].round(2)\n",
    "df_final['dti'] = df_final['dti'].round(4)\n",
    "print(\"- Float columns rounded for better display.\")\n",
    "\n",
    "\n",
    "# --- Final Quick Validation ---\n",
    "print(\"\\n--- Checking final data types before saving ---\")\n",
    "print(df_final.info())\n",
    "\n",
    "print(\"\\n--- Checking final descriptive statistics ---\")\n",
    "print(df_final[['loan_amnt', 'int_rate', 'annual_inc', 'dti']].describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f376950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUCCESS! File 'cleaned_loan_data.csv' was created in the '../data' folder.\n",
      "The file was saved with a comma (,) as the separator and UTF-8 encoding.\n"
     ]
    }
   ],
   "source": [
    "# --- FINAL SAVING CELL ---\n",
    "\n",
    "# Define the output path to the 'data' folder\n",
    "output_folder = '../data' \n",
    "output_filename = 'cleaned_loan_data.csv'\n",
    "output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "# Ensure the target directory exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Save the final, cleaned dataframe\n",
    "# We explicitly set sep=',' to force comma as the separator\n",
    "# and encoding='utf-8' to ensure universal character compatibility.\n",
    "df_final.to_csv(output_path, index=False, sep=',', encoding='utf-8')\n",
    "\n",
    "print(f\"\\nSUCCESS! File '{output_filename}' was created in the '{output_folder}' folder.\")\n",
    "print(\"The file was saved with a comma (,) as the separator and UTF-8 encoding.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b01e8980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STARTING VALIDATION OF THE FINAL 'cleaned_loan_data.csv' FILE ---\n",
      "File 'cleaned_loan_data.csv' loaded successfully for validation.\n",
      "\n",
      "1. STRUCTURE AND DATA TYPES (dtypes):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2260668 entries, 0 to 2260667\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   loan_amnt            int64  \n",
      " 1   term                 int64  \n",
      " 2   int_rate             float64\n",
      " 3   grade                object \n",
      " 4   sub_grade            object \n",
      " 5   emp_length           int64  \n",
      " 6   home_ownership       object \n",
      " 7   annual_inc           float64\n",
      " 8   verification_status  object \n",
      " 9   issue_d              object \n",
      " 10  loan_status          object \n",
      " 11  purpose              object \n",
      " 12  addr_state           object \n",
      " 13  dti                  float64\n",
      " 14  earliest_cr_line     object \n",
      " 15  loan_condition       object \n",
      "dtypes: float64(3), int64(3), object(10)\n",
      "memory usage: 276.0+ MB\n",
      "None\n",
      "--------------------------------------------------\n",
      "\n",
      "2. UNIQUE VALUES IN KEY CATEGORICAL COLUMNS:\n",
      "\n",
      "   Unique values for 'term':\n",
      "   [36 60]\n",
      "\n",
      "   Unique values for 'grade':\n",
      "   ['C' 'B' 'F' 'A' 'E' 'D' 'G']\n",
      "\n",
      "   Unique values for 'emp_length':\n",
      "   [10  3  4  6  1  7  8  5  2  9  0]\n",
      "\n",
      "   Unique values for 'home_ownership':\n",
      "   ['MORTGAGE' 'RENT' 'OWN' 'ANY' 'NONE' 'OTHER']\n",
      "\n",
      "   Unique values for 'verification_status':\n",
      "   ['Not Verified' 'Source Verified' 'Verified']\n",
      "\n",
      "   Unique values for 'loan_condition':\n",
      "   ['Good' 'Bad']\n",
      "\n",
      "   Unique values for 'purpose':\n",
      "   ['debt_consolidation' 'small_business' 'home_improvement' 'major_purchase'\n",
      " 'credit_card' 'other' 'house' 'vacation' 'car' 'medical' 'moving'\n",
      " 'renewable_energy' 'wedding' 'educational']\n",
      "--------------------------------------------------\n",
      "\n",
      "3. DESCRIPTIVE STATISTICS FOR NUMERIC COLUMNS:\n",
      "          loan_amnt      int_rate    annual_inc           dti    emp_length\n",
      "count  2.260668e+06  2.260668e+06  2.260664e+06  2.258957e+06  2.260668e+06\n",
      "mean   1.504693e+04  1.309283e+01  7.799243e+04  1.882420e+01  5.545917e+00\n",
      "std    9.190245e+03  4.832138e+00  1.126962e+05  1.418333e+01  3.883071e+00\n",
      "min    5.000000e+02  5.310000e+00  0.000000e+00 -1.000000e+00  0.000000e+00\n",
      "25%    8.000000e+03  9.490000e+00  4.600000e+04  1.189000e+01  2.000000e+00\n",
      "50%    1.290000e+04  1.262000e+01  6.500000e+04  1.784000e+01  5.000000e+00\n",
      "75%    2.000000e+04  1.599000e+01  9.300000e+04  2.449000e+01  1.000000e+01\n",
      "max    4.000000e+04  3.099000e+01  1.100000e+08  9.990000e+02  1.000000e+01\n",
      "--------------------------------------------------\n",
      "\n",
      "4. COUNT OF NULL VALUES PER COLUMN:\n",
      "loan_amnt                 0\n",
      "term                      0\n",
      "int_rate                  0\n",
      "grade                     0\n",
      "sub_grade                 0\n",
      "emp_length                0\n",
      "home_ownership            0\n",
      "annual_inc                4\n",
      "verification_status       0\n",
      "issue_d                   0\n",
      "loan_status               0\n",
      "purpose                   0\n",
      "addr_state                0\n",
      "dti                    1711\n",
      "earliest_cr_line         29\n",
      "loan_condition            0\n",
      "dtype: int64\n",
      "--------------------------------------------------\n",
      "\n",
      "--- VALIDATION COMPLETE ---\n"
     ]
    }
   ],
   "source": [
    "# --- FINAL VALIDATION CELL ---\n",
    "# Let's load the CSV file we just saved to ensure\n",
    "# it was written and can be read correctly.\n",
    "\n",
    "print(\"\\n--- STARTING VALIDATION OF THE FINAL 'cleaned_loan_data.csv' FILE ---\")\n",
    "\n",
    "try:\n",
    "    # Load the final file for validation\n",
    "    df_validation = pd.read_csv('../data/cleaned_loan_data.csv')\n",
    "    print(\"File 'cleaned_loan_data.csv' loaded successfully for validation.\\n\")\n",
    "\n",
    "    # --- 1. Validate Structure and Data Types ---\n",
    "    print(\"1. STRUCTURE AND DATA TYPES (dtypes):\")\n",
    "    print(df_validation.info())\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # --- 2. Validate Unique Values for Categorical Columns ---\n",
    "    print(\"\\n2. UNIQUE VALUES IN KEY CATEGORICAL COLUMNS:\")\n",
    "    \n",
    "    categorical_columns_to_validate = [\n",
    "        'term', 'grade', 'emp_length', 'home_ownership', \n",
    "        'verification_status', 'loan_condition', 'purpose'\n",
    "    ]\n",
    "    \n",
    "    for col in categorical_columns_to_validate:\n",
    "        print(f\"\\n   Unique values for '{col}':\")\n",
    "        # We use .unique() to see all possible values\n",
    "        print(f\"   {df_validation[col].unique()}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # --- 3. Validate Range and Statistics for Numeric Columns ---\n",
    "    print(\"\\n3. DESCRIPTIVE STATISTICS FOR NUMERIC COLUMNS:\")\n",
    "    # .describe() gives us count, mean, std, min, max, and quartiles.\n",
    "    # This is great for identifying outliers or scaling issues.\n",
    "    numeric_columns_to_validate = [\n",
    "        'loan_amnt', 'int_rate', 'annual_inc', 'dti', 'emp_length'\n",
    "    ]\n",
    "    print(df_validation[numeric_columns_to_validate].describe())\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # --- 4. Check for Null Values ---\n",
    "    print(\"\\n4. COUNT OF NULL VALUES PER COLUMN:\")\n",
    "    print(df_validation.isnull().sum())\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    print(\"\\n--- VALIDATION COMPLETE ---\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: The file 'cleaned_loan_data.csv' was not found in the '../data' folder.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during validation: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
